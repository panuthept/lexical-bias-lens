import random
from tqdm import tqdm
from lens import LexicalBiasLens


class LexicalBiasExploitator(LexicalBiasLens):
    def permute(
        self, 
        samples: list, 
        target_label: str,
        top_k: int = 10,
        n: int = 1,
    ):
        assert self.bias_profile is not None, "Please create_profile() before permuting samples."
        assert target_label in self.available_labels, f"target_label '{target_label}' not found in available labels: {self.available_labels}"
        assert (isinstance(n, int) and n > 0), "n must be a positive integer."

        bias_tokens = self.find_bias_keywords(target_label=target_label, top_k=top_k, ranking_order="decending")
        bias_tokens = [token for token, score in bias_tokens]

        permuted_samples = samples.copy()

        for i in range(len(permuted_samples)):
            tokens = permuted_samples[i].copy()
            permuted_tokens = tokens
            suffix_tokens = [random.choice(bias_tokens) for _ in range(n)]
            for j in range(len(suffix_tokens)):
                permuted_tokens = [*permuted_tokens, *suffix_tokens[j]]
            permuted_samples[i] = permuted_tokens
        return permuted_samples


if __name__ == "__main__":
    import os
    from datasets import load_dataset
    from transformers import AutoTokenizer

    save_path = "saves/aisingapore/1M_SEA-Guard_qwen3-8b_Non_Bias/train_refined_v1_qa_pass_only"
    tokenizer = AutoTokenizer.from_pretrained("aisingapore/1M_SEA-Guard_qwen3-8b_Non_Bias")

    dataset_sources = [
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Indonesia", "train_refined_v1_qa_pass_only"),
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Malaysia", "train_refined_v1_qa_pass_only"),
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Myanmar", "train_refined_v1_qa_pass_only"),
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Philippines", "train_refined_v1_qa_pass_only"),
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Singapore", "train_refined_v1_qa_pass_only"),
        ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Thailand", "train_refined_v1_qa_pass_only"),
        # ("aisingapore/SEA-Safeguard-Train-Cultural-v3", "Vietnam", "train_refined_v1_qa_pass_only"),
    ]

    if not os.path.exists(save_path):
        exploitator = LexicalBiasExploitator(max_n=1, metric="LMI")

        labels = []
        samples = []
        for repo, subset, split in dataset_sources:
            dataset = load_dataset(repo, subset, split=split)
        
            for sample in tqdm(dataset):
                if sample["response"] is None:
                    input = sample['prompt']
                    label = sample['prompt_label']
                else:
                    input = (sample['prompt'] + "\n" + sample['response'])
                    label = sample['response_label']
                tokens = tokenizer.tokenize(input)
                samples.append(tokens)
                labels.append(label)

                if len(samples) >= 10000:
                    exploitator.fit(samples, labels, verbose=False)
                    exploitator.save(save_path)
                    labels = []
                    samples = []
    else:
        exploitator = LexicalBiasExploitator.load(save_path, metric="LMI")

    keywords_scores = exploitator.find_bias_keywords(target_label="Unsafe", top_k=20, ranking_order="decending")
    keywords_scores = [(tokenizer.decode(tokenizer.convert_tokens_to_ids(token)), score) for token, score in keywords_scores]
    print(f"Top 20 bias keywords for 'Unsafe': {keywords_scores}")
    print()
    keywords_scores = exploitator.find_bias_keywords(target_label="Safe", top_k=20, ranking_order="decending")
    keywords_scores = [(tokenizer.decode(tokenizer.convert_tokens_to_ids(token)), score) for token, score in keywords_scores]
    print(f"Top 20 bias keywords for 'Safe': {keywords_scores}")

    # Testing permute function
    dataset = load_dataset("aisingapore/SEASafeguardBench", "cultural_content_generation", split="TH_EN")

    label_mapping = {
        "Safe": "Safe",
        "Sensitive": "Sensitive",
        "Unsafe": "Unsafe",
        "Harmful": "Unsafe",
    }

    labels = []
    samples = []
    for sample in tqdm(dataset):
        # Prompt-only samples
        # English language
        input = sample['en_prompt']
        label = label_mapping[sample['prompt_label']]
        tokens = tokenizer.tokenize(input)
        samples.append(tokens)
        labels.append(label)
        # Local Language
        input = sample['local_prompt']
        label = label_mapping[sample['prompt_label']]
        tokens = tokenizer.tokenize(input)
        samples.append(tokens)
        labels.append(label)

        # Prompt + Response samples
        # English language
        input = (sample['en_prompt'] + "\n" + sample['en_response'])
        label = label_mapping[sample['response_label']]
        tokens = tokenizer.tokenize(input)
        samples.append(tokens)
        labels.append(label)
        # Local Language
        input = (sample['local_prompt'] + "\n" + sample['local_response'])
        label = label_mapping[sample['response_label']]
        tokens = tokenizer.tokenize(input)
        samples.append(tokens)
        labels.append(label)

    exploitator.create_profile(samples, labels)

    unsafe_samples = [sample for sample, label in zip(samples, labels) if label == "Unsafe"]
    before_pred_labels = exploitator.predict(samples=unsafe_samples)

    permuted_samples = exploitator.permute(unsafe_samples, target_label="Safe", n=5, top_k=1)

    after_pred_labels = exploitator.predict(samples=permuted_samples)
    for i in range(10):
        print("Original Sample:", tokenizer.decode(tokenizer.convert_tokens_to_ids(unsafe_samples[i])))
        print("Original Label:", labels[i])
        print("Predicted Label Before Permutation:", before_pred_labels[i])
        print("Permuted Sample:", tokenizer.decode(tokenizer.convert_tokens_to_ids(permuted_samples[i])))
        print("Predicted Label After Permutation:", after_pred_labels[i])
        print("-----")